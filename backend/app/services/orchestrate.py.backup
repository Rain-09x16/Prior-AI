"""
Orchestration Conductor - Main workflow coordinator.

This is the INTEGRATION POINT between fullstack and AI/ML code.
It orchestrates the complete analysis workflow by calling:
1. Document Parser (fullstack)
2. Claim Extractor (AI/ML)
3. Patent Searcher (fullstack)
4. Similarity Scorer (AI/ML)
5. Recommendation Generator (AI/ML)
"""
from typing import Dict
import json
from datetime import datetime
from sqlalchemy.orm import Session

# Import fullstack services
from app.services.patent_searcher import PatentSearcher
from app.models import Analysis, Patent, OrchestrateLog

# Import AI/ML services (stubs for now, AI/ML dev will implement)
from app.ml_services.claim_extractor import ClaimExtractor
from app.ml_services.similarity_scorer import SimilarityScorer
from app.ml_services.recommender import RecommendationGenerator

from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class OrchestrateConductor:
    """
    Orchestrate the full prior art analysis workflow.

    This class coordinates between fullstack and AI/ML components.
    """

    def __init__(self, db_session: Session):
        """
        Initialize the orchestration conductor.

        Args:
            db_session: Database session for logging and storing results
        """
        self.db = db_session

        # Initialize AI/ML services (AI/ML developer implements these)
        logger.info("Initializing AI/ML services...")
        self.claim_extractor = ClaimExtractor()
        self.similarity_scorer = SimilarityScorer()
        self.recommender = RecommendationGenerator()

        # Initialize fullstack services
        logger.info("Initializing fullstack services...")
        self.patent_searcher = PatentSearcher()

        logger.info("Orchestration Conductor initialized")

    async def run_analysis(self, analysis_id: int, document_text: str) -> Dict:
        """
        Run the complete analysis workflow.

        NEW WORKFLOW (v2.1):
        0. Assess Patentability (AI/ML) - NEW STEP
           - If NOT patentable: Return early with recommendations, skip expensive search
           - If patentable: Continue with normal flow
        1. Extract claims from document (AI/ML)
        2. Search for patents (Fullstack)
        3. Score patent similarity (AI/ML)
        4. Generate recommendation (AI/ML)
        5. Return results

        Args:
            analysis_id: Database ID of the analysis
            document_text: Parsed document text

        Returns:
            Dictionary with analysis results
        """
        logger.info(f"Starting analysis workflow for analysis_id={analysis_id}")

        try:
            # NEW STEP 0: Assess Patentability (v2.1)
            logger.info("Step 0 (NEW): Assessing patentability...")
            patentability = await self._run_skill(
                analysis_id,
                "assess_patentability",
                lambda: self.claim_extractor.assess_patentability(document_text)
            )
            logger.info(f"Patentability: {patentability.get('isPatentable')} (confidence: {patentability.get('confidence')}%)")

            # Save patentability results to database
            analysis = self.db.query(Analysis).filter(Analysis.id == analysis_id).first()
            if analysis:
                analysis.is_patentable = patentability.get('isPatentable')
                analysis.patentability_confidence = patentability.get('confidence')
                analysis.missing_elements = json.dumps(patentability.get('missingElements', []))
                self.db.commit()
                logger.info("Saved patentability assessment to database")

            # If NOT patentable, stop here and return warning (save costs!)
            if not patentability.get('isPatentable'):
                logger.warning("Disclosure is NOT patentable - stopping analysis to save costs")

                if analysis:
                    analysis.status = 'completed'
                    analysis.reasoning = "Disclosure appears to be publishable research but not patentable. See patentability assessment for details."
                    analysis.recommendation = 'reject'
                    analysis.novelty_score = 0.0
                    analysis.completed_at = datetime.utcnow()
                    self.db.commit()

                return {
                    'patentabilityAssessment': patentability,
                    'warning': 'Disclosure appears to be publishable but not patentable',
                    'skipPriorArt': True,
                    'recommendation': 'reject',
                    'reasoning': 'Based on patentability assessment, this disclosure lacks key elements required for a patent. Consider revising the disclosure or publishing as research instead.'
                }

            # PATENTABLE - Continue with normal workflow
            logger.info("Disclosure is patentable - proceeding with prior art search")

            # Step 1: Extract Claims (AI/ML)
            logger.info("Step 1: Extracting claims from disclosure...")
            claims = await self._run_skill(
                analysis_id,
                "extract_claims",
                lambda: self.claim_extractor.extract(document_text)
            )
            logger.info(f"Extracted {len(claims.get('keywords', []))} keywords and {len(claims.get('innovations', []))} innovations")

            # Step 2: Search Patents (Fullstack)
            logger.info("Step 2: Searching patent database...")
            patents = await self._run_skill(
                analysis_id,
                "search_patents",
                lambda: self.patent_searcher.search(
                    keywords=claims.get('keywords', []),
                    ipc_codes=claims.get('ipcClassifications', []),
                    max_results=100
                )
            )
            logger.info(f"Found {len(patents)} patents")

            # Step 3: Score Similarity (AI/ML)
            logger.info("Step 3: Scoring patent similarity...")
            scored_patents = await self._run_skill(
                analysis_id,
                "score_similarity",
                lambda: self.similarity_scorer.score_multiple_patents(claims, patents)
            )
            logger.info(f"Scored {len(scored_patents)} patents")

            # Step 4: Generate Recommendation (AI/ML)
            logger.info("Step 4: Generating recommendation...")
            recommendation = await self._run_skill(
                analysis_id,
                "generate_recommendation",
                lambda: self.recommender.generate(claims, scored_patents)
            )
            logger.info(f"Recommendation: {recommendation.get('recommendation')} (novelty: {recommendation.get('noveltyScore')})")

            # Compile final results (including patentability assessment)
            results = {
                'patentabilityAssessment': patentability,
                'extractedClaims': claims,
                'patents': scored_patents[:20],  # Return top 20 patents
                'noveltyScore': recommendation.get('noveltyScore'),
                'recommendation': recommendation.get('recommendation'),
                'reasoning': recommendation.get('reasoning'),
                'suggestedClaimFocus': recommendation.get('suggestedClaimFocus', [])
            }

            logger.info(f"Analysis workflow completed for analysis_id={analysis_id}")
            return results

        except Exception as e:
            logger.error(f"Analysis workflow failed: {str(e)}")
            self._log_error(analysis_id, str(e))
            raise

    async def _run_skill(self, analysis_id: int, skill_name: str, skill_function):
        """
        Execute a skill and log to orchestrate_logs table.

        This method wraps each step of the workflow for tracking and debugging.

        Args:
            analysis_id: Database ID of the analysis
            skill_name: Name of the skill being executed
            skill_function: Lambda/function to execute

        Returns:
            Result from skill_function
        """
        logger.info(f"Executing skill: {skill_name}")

        # Create orchestration log entry
        log = OrchestrateLog(
            analysis_id=analysis_id,
            skill_name=skill_name,
            status="started",
            started_at=datetime.utcnow()
        )
        self.db.add(log)
        self.db.commit()

        try:
            # Execute the skill
            start_time = datetime.utcnow()
            result = skill_function()
            end_time = datetime.utcnow()

            # Update log with success
            log.status = "completed"
            log.completed_at = end_time
            log.output_data = json.dumps(
                {"status": "success", "duration_seconds": (end_time - start_time).total_seconds()},
                default=str
            )
            self.db.commit()

            logger.info(f"Skill {skill_name} completed successfully")
            return result

        except Exception as e:
            # Update log with failure
            log.status = "failed"
            log.completed_at = datetime.utcnow()
            log.error_message = str(e)
            self.db.commit()

            logger.error(f"Skill {skill_name} failed: {str(e)}")
            raise

    def _log_error(self, analysis_id: int, error_message: str):
        """Log error to orchestrate_logs."""
        try:
            log = OrchestrateLog(
                analysis_id=analysis_id,
                skill_name="workflow_error",
                status="failed",
                error_message=error_message,
                started_at=datetime.utcnow(),
                completed_at=datetime.utcnow()
            )
            self.db.add(log)
            self.db.commit()
        except Exception as e:
            logger.error(f"Failed to log error: {str(e)}")
